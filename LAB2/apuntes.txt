Stremming -> normalizar textos 
1. convertir texto en tokens.

python3 IndexFilesPreprocess.py --index novels_whitespace --path /home/he/Desktop/caim/session1ESZipfHeaps/novels --token whitespace
python3 IndexFilesPreprocess.py --index novels_whitespace --path ./novels --token whitespace
python3 IndexFilesPreprocess.py --index news --path /novels --token whitespace


TOKENIZER -> standard tokenizer, 

cargar los indices de newletter para una meor analisis. 
Lo tekenizamos, y hacemos stemming. 

IndexFilesPreprocess-> hace tokenizacion y filtrado 
--token opciones
con countpy miramos como varia el numero de parabla a medida que variamos "opciones"

coger el tokenizer mas agressivo, y activar filtros: lowercase, asciifolfing.

contestar preguntas elegiendo los filtros sabiamente.

Tipos de filtros:   
    - snowball: hace un stem de un idioma con Snowball-generated stemmer
    - porter stem: hace un stem del ingles muy agressivo (elimina sufijos)
    - kstem: hace un stem menos agresivo que porter stem

Para los filtros intentar buscar la mejor combinaci√≥n de filtros posibles.