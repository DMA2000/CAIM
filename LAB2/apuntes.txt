Stremming -> normalizar textos 
1. convertir texto en tokens.

python3 IndexFilesPreprocess.py --index novels_whitespace --path /home/he/Desktop/caim/session1ESZipfHeaps/novels --token whitespace
python3 IndexFilesPreprocess.py --index novels_whitespace --path ./novels --token whitespace
python3 IndexFilesPreprocess.py --index news --path /novels --token whitespace

python3 TFIDFViewer.py --index novels --file pg1410.txt pg1410.txt

TOKENIZER -> standard tokenizer, 

cargar los indices de newletter para una meor analisis. 
Lo tekenizamos, y hacemos stemming. 

IndexFilesPreprocess-> hace tokenizacion y filtrado 
--token opciones
con countpy miramos como varia el numero de parabla a medida que variamos "opciones"

coger el tokenizer mas agressivo, y activar filtros: lowercase, asciifolfing.

contestar preguntas elegiendo los filtros sabiamente. 